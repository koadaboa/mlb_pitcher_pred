# src/features/selection.py
import pandas as pd
import numpy as np
import logging

logger = logging.getLogger(__name__) # Use standard logging

# Define the columns to exclude BEFORE any importance calculation
# (Using the list you provided previously, plus umpire features)
BASE_EXCLUDE_COLS = [
    # Identifiers / Non-Features
    'index', '', 'pitcher_id', 'player_name', 'game_pk', 'home_team', 'away_team', 'opponent', # Added opponent based on user feedback
    'opponent_team_name', 'game_date', 'season', 'game_month', 'year',
    'p_throws', 'stand', 'team', 'Team', # Exclude original categoricals now that encoded versions exist
    'opp_base_team', 'opp_adv_team', 'opp_adv_opponent', 'ballpark',

    # Target Variable
    'strikeouts',

    # --- DIRECT LEAKAGE COLUMNS (Derived from target game outcome/process) ---
    'batters_faced', 'total_pitches', 'innings_pitched',
    'avg_velocity', 'max_velocity', 'avg_spin_rate', 'avg_horizontal_break', 'avg_vertical_break',
    'k_per_9', 'k_percent', 'swinging_strike_percent', 'called_strike_percent',
    'zone_percent', 'fastball_percent', 'breaking_percent', 'offspeed_percent',
    'total_swinging_strikes', 'total_called_strikes', 'total_fastballs',
    'total_breaking', 'total_offspeed', 'total_in_zone',
    'pa_vs_rhb', 'k_vs_rhb', 'k_percent_vs_rhb',
    'pa_vs_lhb', 'k_vs_lhb', 'k_percent_vs_lhb',
    'platoon_split_k_pct',
    # -----------------------------------------------------------------------

    # --- UMPIRE FEATURES (Exclude for now) ---
    'umpire', # Original umpire name if present
    'umpire_encoded', # Encoded umpire feature
    'umpire_historical_k_per_9', # Historical umpire stats
    'pitcher_umpire_k_boost', # Interaction feature
    # Add any other umpire-specific features generated by your pipeline
    # -----------------------------------------

    # Other potential post-game info or less relevant features
    'inning', 'score_differential', 'is_close_game', 'is_playoff',

    # Low importance / redundant features (can be reviewed based on importance later)
    #'is_home', # Keep the numerical one? Or use encoded? Keep encoded -> 'is_home' should be excluded if 'home_team_encoded' exists
    'rest_days_6_more', 'rest_days_4_less', 'rest_days_5', # days_since_last_game is likely better
    'is_month_3', 'is_month_4', 'is_month_5', 'is_month_6', 'is_month_7', 'is_month_8', 'is_month_9', 'is_month_10',
    'throws_right', # p_throws_encoded should exist

    # Imputation flags (usually not predictive)
    'avg_velocity_imputed_median', 'max_velocity_imputed_median', 'avg_spin_rate_imputed_median',
    'avg_horizontal_break_imputed_median', 'avg_vertical_break_imputed_median',
    'avg_velocity_imputed_knn', 'avg_spin_rate_imputed_knn',
    'avg_horizontal_break_imputed_knn', 'avg_vertical_break_imputed_knn',

    # Some specific lagged/change features marked for exclusion (review based on performance)
    'last_game_strikeouts', 'strikeout_change', 'strikeouts_lag1',
    'batters_faced_change', 'k_per_9_pct_change', 'k_per_9_lag1', 'batters_faced_lag1', 'k_per_9_change',
    'innings_pitched_change', 'ewma_3g_strikeouts',
]

def select_features(df, target_variable, exclude_cols=None):
    """
    Selects numeric features suitable for training, excluding a predefined list.

    Args:
        df (pd.DataFrame): The input dataframe containing all features.
        target_variable (str): The name of the target variable column.
        exclude_cols (list, optional): A list of columns to explicitly exclude.
                                       Defaults to BASE_EXCLUDE_COLS defined above.

    Returns:
        tuple: (list_of_selected_feature_names, pd.DataFrame_subset_with_features_and_target)
               Returns ([], pd.DataFrame()) if input df is invalid or no features are selected.
    """
    if df is None or df.empty:
        logger.error("Input DataFrame is None or empty.")
        return [], pd.DataFrame()

    if exclude_cols is None:
        exclude_cols = BASE_EXCLUDE_COLS

    # Create a set for efficient lookup, handling potential None values in df.columns
    df_cols_set = set(col for col in df.columns if col is not None)
    exclude_set = set(exclude_cols)

    # Ensure target variable is in the exclusion list (if it exists in df)
    if target_variable in df_cols_set and target_variable not in exclude_set:
        exclude_set.add(target_variable)

    # Select numeric columns ONLY
    numeric_cols = df.select_dtypes(include=np.number).columns.tolist()

    # Find features that are numeric AND not in the exclusion list
    feature_cols = [
        col for col in numeric_cols
        if col not in exclude_set
        and col in df_cols_set # Ensure the column actually exists in the df
    ]

    # Check for infinite values AFTER identifying potential feature columns
    has_inf = False
    if feature_cols: # Check if list is not empty
        df_subset = df[feature_cols]
        if not df_subset.empty:
            try:
                inf_mask = np.isinf(df_subset).any()
                if inf_mask.any():
                    inf_cols = df_subset.columns[inf_mask].tolist()
                    logger.warning(f"Infinite values found in potential feature columns: {inf_cols}. Consider handling them.")
                    has_inf = True
            except TypeError as e:
                 logger.error(f"TypeError checking for infinite values (potentially mixed types): {e}")
                 # Handle or log columns causing issues if possible
                 pass # Continue without inf check if types are mixed causing error


    if not feature_cols:
        logger.error("No numeric features selected after applying exclusions.")
        return [], pd.DataFrame()

    logger.info(f"Selected {len(feature_cols)} numeric features after initial exclusion (including umpire features).")

    # Return the list of feature names and a DataFrame subset containing
    # only these features and the target variable (if present)
    columns_to_return = feature_cols + ([target_variable] if target_variable in df_cols_set else [])
    # Ensure all columns to return actually exist before slicing
    columns_to_return = [col for col in columns_to_return if col in df_cols_set]
    selected_df_subset = df[columns_to_return].copy()

    return feature_cols, selected_df_subset

